{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-roman",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "elect-tuition",
    "outputId": "36f47ec4-b305-4266-9edc-a485fc5bb4a9"
   },
   "outputs": [],
   "source": [
    "## Author: Abhishek Sinha, Tata Institute of Fundamental Research, Mumbai, India\n",
    "## All rights reserved\n",
    "\n",
    "## This code is meant to be run on Google Colab\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.core.common import flatten\n",
    "np.random.seed(16) ## e.g., put seed=7\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device('cpu') ## Running on cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-nickel",
   "metadata": {
    "id": "outdoor-bargain"
   },
   "outputs": [],
   "source": [
    "class COCO:\n",
    "    def __init__(self, n, T, lambda_param): ### n denotes the dimension of input\n",
    "        #self.D=np.sqrt(2) ### D denotes the Euclidean diameter of the feasible set, which is sqrt(2) for simplex\n",
    "        self.D=10 ### Diameter of the action set\n",
    "        self.n=n\n",
    "        self.x=np.array(proj(np.random.rand(n))).reshape(-1,1) ### n denotes the input dimension\n",
    "        #self.x=np.array(proj(np.ones(n)/n)).reshape(-1,1)\n",
    "        self.step_size=0\n",
    "        self.grad_sum_sq=0.001 ### internal variable needed to compute the step size\n",
    "        self.sum_x=self.x ### internal variable required to get the average prediction\n",
    "        self.Q=0 ### initializing the cumulative constraint violation\n",
    "        self.TotalCost=0 ### initializing the total cost incurred\n",
    "        #self.Lambda=1.0/(2.0*np.sqrt(T)) ## the default setting\n",
    "        #self.Lambda=0.038 ## custom setting for the credit card fraud detection dataset\n",
    "        self.Lambda=lambda_param\n",
    "        self.V=1   ## setting the required hyper parameters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def predict_COCO(self, grad):\n",
    "        self.x=np.array(proj(self.x-self.step_size*grad)).reshape(-1,1)\n",
    "        return\n",
    "\n",
    "    def update_COCO(self, cost_val, constr_val):\n",
    "        self.Q = self.Q+constr_val\n",
    "        self.TotalCost=self.TotalCost+cost_val ## updating CCV and cost\n",
    "        self.sum_x=self.sum_x+self.x\n",
    "\n",
    "    def surrogate_cost_grad(self, cost_grad, constr_grad): # returns the gradient of the surrogate cost function at x\n",
    "        grad=self.V*cost_grad.reshape(-1,1)+self.Lambda*np.exp(self.Lambda*self.Q)*constr_grad.reshape(-1,1)\n",
    "        self.grad_sum_sq=self.grad_sum_sq+np.linalg.norm(grad)**2\n",
    "        self.step_size=self.D/np.sqrt(2.0*self.grad_sum_sq) ### selecting step sizes using AdaGrad\n",
    "        return grad.reshape(-1,1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-italic",
   "metadata": {
    "id": "wicked-bundle"
   },
   "outputs": [],
   "source": [
    "class NN:\n",
    "    ## implements the case when the cost and constraint functions are given by a Neural Network\n",
    "    def __init__(self):\n",
    "        self.id='NN'\n",
    "        self.problem_class='classification'\n",
    "        self.t=-1 ### counter indicates the current round number\n",
    "        self.MISS=0 ## counter to keep track of number of misses\n",
    "        self.N1=0 ## count of examples belonging to class 1\n",
    "        self.FA=0 ### counter to keep track of number of FA\n",
    "        self.N0=0 ## count of examples belonging to class 0\n",
    "\n",
    "        self.data=pd.read_csv('/content/drive/MyDrive/creditcard.csv')\n",
    "        self.data=self.data.sample(frac=1) ## randomly shuffling the rows\n",
    "        self.z=np.array(self.data.iloc[:,1:30]) ## z denotes the feature vector matrix\n",
    "        self.y=np.array(self.data['Class'])    ## y denotes the column of labels\n",
    "\n",
    "        ##--------------------\n",
    "\n",
    "        object= StandardScaler()\n",
    "        self.z= object.fit_transform(self.z) ## preprocessing the feature vectors\n",
    "\n",
    "        #### -------------\n",
    "        ## configuring the NN architecture and the loss function\n",
    "\n",
    "        self.N, self.D_in, self.H, self.D_out = 1, self.z.shape[1], 10, 1 ## 10 hidden layer width, 4 dimensional feature\n",
    "\n",
    "        self.model = torch.nn.Sequential(\n",
    "          torch.nn.Linear(self.D_in, self.H),\n",
    "          #torch.nn.ReLU(),\n",
    "          torch.nn.Sigmoid(),\n",
    "          #torch.nn.Linear(self.H, self.H),\n",
    "          #torch.nn.ReLU(),\n",
    "          torch.nn.Linear(self.H, self.D_out),\n",
    "          torch.nn.Sigmoid(), ## the output layer\n",
    "        ).to(device)\n",
    "\n",
    "        self.loss_fn = torch.nn.BCELoss() ## remember - it is simply the negative log likelihood - training via Max likelihood\n",
    "\n",
    "    def update_grad(self):\n",
    "        self.t+=1\n",
    "        self.model.zero_grad()\n",
    "        self.hat_y=self.model(torch.tensor(self.z[self.t,:]).to(torch.float32)) ## predicted value\n",
    "        self.hat_y=torch.clamp(self.hat_y, min=1e-7, max=1-1e-7) ## avoiding extreme values for numerical stability\n",
    "        self.loss=self.loss_fn(torch.squeeze(self.hat_y), torch.tensor(self.y[self.t]).to(torch.float32))\n",
    "        self.loss.backward()\n",
    "        gradients = []\n",
    "        for param in self.model.parameters():\n",
    "            if param.grad is not None:\n",
    "                gradients.append(param.grad.view(-1))\n",
    "        self.grad_vector = np.array(torch.cat(gradients))\n",
    "\n",
    "        ## Updating the performance metrics\n",
    "        self.N0+=(1-self.y[self.t])\n",
    "        self.FA+=(1-self.y[self.t])*self.hat_y\n",
    "        self.N1+=self.y[self.t]\n",
    "        self.MISS+=self.y[self.t]*(1-self.hat_y)\n",
    "\n",
    "\n",
    "    def grad_f(self, x):\n",
    "        if(self.y[self.t]==0):\n",
    "            return self.grad_vector\n",
    "        else:\n",
    "            return np.zeros(len(self.grad_vector))\n",
    "\n",
    "\n",
    "    def grad_g(self, x):\n",
    "        if(self.y[self.t]==1):\n",
    "            return self.grad_vector\n",
    "        else:\n",
    "            return np.zeros(len(self.grad_vector))\n",
    "\n",
    "\n",
    "\n",
    "    def f_val(self, x):\n",
    "        return -(1-self.y[self.t])*torch.log(1.0-self.hat_y) ## f= -(1-y)log(1-y_hat) (Liklihood value)\n",
    "\n",
    "\n",
    "    def g_val(self, x):  ## g = -y log(y_hat) assuming bias=0\n",
    "        return -self.y[self.t]*(min(0.0, torch.log(self.hat_y)-torch.log(torch.tensor(1.0))))\n",
    "\n",
    "\n",
    "\n",
    "## Assigning the parameters returned by COCO to the NN\n",
    "def assign_parameters(model, vector):\n",
    "    \"\"\"\n",
    "    Assign the parameters of a PyTorch neural network using the given vector.\n",
    "\n",
    "    Args:\n",
    "    - model (nn.Module): The PyTorch neural network model.\n",
    "    - vector (list or numpy array or torch tensor): The vector containing the new parameters.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    if not isinstance(vector, torch.Tensor):\n",
    "        vector = torch.tensor(vector, dtype=torch.float32)\n",
    "\n",
    "    # Ensure the vector has the same number of elements as the model's parameters\n",
    "    params = torch.cat([p.view(-1) for p in model.model.parameters()])\n",
    "    assert params.numel() == vector.numel(), \"Vector size must match the number of model parameters\"\n",
    "\n",
    "    # Assign the parameters\n",
    "    index = 0\n",
    "    for p in model.model.parameters():\n",
    "        numel = p.numel()\n",
    "        p.data = vector[index:index+numel].view(p.size())\n",
    "        index += numel\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-translation",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "id": "affected-sphere",
    "outputId": "90b52b52-5932-427e-959a-977fdbe99cbf"
   },
   "outputs": [],
   "source": [
    "### Driver code\n",
    "\n",
    "## It might need a few hours to finish execution depending on the number of different lambda parameter settings to be tested in\n",
    "## the hyper_parameter_lambda variable below. If necessary, reduce this number.\n",
    "#---------------------------\n",
    "\n",
    "hyper_parameter_lambda=np.linspace(0.01,0.05,30)\n",
    "ROC=np.zeros([0,2])\n",
    "for lambda_param in hyper_parameter_lambda: # sweep of the hyper-parameter lambda\n",
    "    adversary=NN()\n",
    "\n",
    "    if adversary.id=='2Player':\n",
    "        n=100\n",
    "        T=100000\n",
    "        from projection import projection_simplex_bisection as proj ### loading the simplex projection module\n",
    "    elif adversary.id=='banknote':\n",
    "        T, n=adversary.z.shape\n",
    "        from projection import euclidean_projection as proj ### loading the Euclidean projection module\n",
    "    elif adversary.id=='linsep':\n",
    "        T, n=adversary.z.shape\n",
    "        from projection import euclidean_projection as proj ### loading the Euclidean projection module\n",
    "    elif adversary.id=='iris':\n",
    "        T, n=adversary.z.shape\n",
    "        from projection import euclidean_projection as proj ### loading the Euclidean projection module\n",
    "    elif adversary.id=='NN':\n",
    "        T=adversary.z.shape[0]\n",
    "        grad_vec=[]\n",
    "        for param in adversary.model.parameters():\n",
    "            grad_vec.append(np.array(param.data))\n",
    "        n=len(list(flatten(grad_vec))) ## counting the number of parameters\n",
    "        from projection import euclidean_projection as proj ### loading the Euclidean projection module\n",
    "    ##########################if\n",
    "\n",
    "\n",
    "    coco = COCO(n,T, lambda_param) ### Algorithm object\n",
    "\n",
    "\n",
    "    cost_vec=np.zeros([1,T])\n",
    "    violation_vec=np.zeros([1,T]) ### Arrays to store the cumulative cost and violation incurred by COCO\n",
    "    regret_vec=np.zeros([1,T])\n",
    "\n",
    "    for t in range(T):\n",
    "        current_action=coco.x # getting the current action of the algorithm\n",
    "\n",
    "        ## assigning the parameters to the NN object\n",
    "\n",
    "        if adversary.id=='NN':\n",
    "            assign_parameters(adversary, current_action)\n",
    "            adversary.update_grad()\n",
    "\n",
    "        ## Calling adversary to get its choice of cost and constraint functions\n",
    "        cost_grad=adversary.grad_f(current_action)\n",
    "        constr_grad=adversary.grad_g(current_action)\n",
    "        cost_val=adversary.f_val(current_action)\n",
    "        constr_val=adversary.g_val(current_action)  ### getting adversary's choices\n",
    "\n",
    "\n",
    "        if adversary.id=='NN':\n",
    "            constr_val=constr_val.item()\n",
    "\n",
    "        ## Calling COCO to update its internal states and to determine its next action\n",
    "        coco.update_COCO(cost_val, constr_val) ### updating internal states of the algorithm\n",
    "        surrogate_cost_grad=coco.surrogate_cost_grad(cost_grad, constr_grad) ### computing the gradient of the surrogate cost\n",
    "\n",
    "        coco.predict_COCO(surrogate_cost_grad)  ### predicting the next_action\n",
    "\n",
    "        #### recording the statistics\n",
    "        cost_vec[0,t]=coco.TotalCost\n",
    "        violation_vec[0,t]=coco.Q\n",
    "        if adversary.problem_class=='game':\n",
    "            regret_vec[0,t]=coco.TotalCost - min(adversary.cost_grad_sum) ## this is a little erroneous as it computes regret over the entire admissible set\n",
    "\n",
    "     #### computing the number of classification errors\n",
    "    if adversary.problem_class=='classification':\n",
    "        #print('False Positive rate:',  adversary.FA/adversary.N0, 'False Negative rate:', adversary.MISS/adversary.N1)\n",
    "        FP=adversary.FA/adversary.N0\n",
    "        FN=adversary.MISS/adversary.N1\n",
    "        FPR=FP\n",
    "        TPR=1-FN\n",
    "        new_rate=[FPR, TPR]\n",
    "        # Convert each tensor to a NumPy array\n",
    "        numpy_array_list = [tensor.detach().numpy() for tensor in new_rate]\n",
    "        rate_array = np.concatenate(numpy_array_list)\n",
    "        print(rate_array)\n",
    "        ROC = np.vstack([ROC, rate_array])\n",
    "\n",
    "\n",
    "# Save the ROC values to a file for plotting the data\n",
    "np.save(\"ROC_data2.dat\", ROC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-bahrain",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "id": "under-mechanism",
    "outputId": "ac5dacb7-0c2d-41e4-e8bb-885c85984422"
   },
   "outputs": [],
   "source": [
    "## Plots the pre-computed result stored in data/ROC_data. If you want to plot the above results, simply replace this\n",
    "## file with the new version\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['text.usetex'] = False\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#plt.rcParams['text.usetex'] = True\n",
    "#sns.set(style='ticks', palette='Set2')\n",
    "sns.set()\n",
    "\n",
    "sns.set_theme(\"paper\")\n",
    "sns.set_style(\"dark\")\n",
    "ROC=pd.read_csv('/content/drive/MyDrive/data/ROC_data', sep='\\s+')\n",
    "ROC=ROC.sort_values('FPR')\n",
    "plt.axis([0.01, 1.0, 0.6, 1])\n",
    "\n",
    "AUC = np.trapz(ROC['TPR'], ROC['FPR'])\n",
    "print(\"Area under the ROC curve is:\", AUC)\n",
    "\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
    "plt.plot(ROC['FPR'], ROC['TPR'], linewidth = 2.0)\n",
    "plt.grid(linestyle = '--', linewidth = 0.7)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.suptitle('ROC curve', fontsize=20)\n",
    "plt.fill_between(ROC['FPR'], ROC['TPR'], color='lightsteelblue', alpha=0.5, label=f'Area under the ROC curve= {AUC:.2f}')\n",
    "plt.legend(loc='lower right', fontsize=14)\n",
    "plt.savefig('ROC_plt.pdf', dpi=1000)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
