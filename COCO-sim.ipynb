{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "finite-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading the required libraries \n",
    "import numpy as np\n",
    "from projection_simplex import projection_simplex_bisection as proj ### loading the simplex projection module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "suited-acquisition",
   "metadata": {},
   "outputs": [],
   "source": [
    "class COCO:\n",
    "    def __init__(self, n, T): ### n denotes the dimension of input\n",
    "        self.D=np.sqrt(2) ### D denotes the Euclidean diameter of the feasible set, which is sqrt(2) for simplex\n",
    "        self.n=n \n",
    "        self.x=np.array(proj(np.random.rand(n))).reshape(-1,1) ### n denotes the input dimension\n",
    "        self.step_size=0\n",
    "        self.grad_sum_sq=0 ### internal variable needed to compute the step size\n",
    "        self.Q=0 ### initializing the cumulative constraint violation\n",
    "        self.TotalCost=0 ### initializing the total cost incurred\n",
    "        self.Lambda=1.0/(2*np.sqrt(T)) \n",
    "        self.V=1   ## setting the required parameters\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    def predict_COCO(self, grad):\n",
    "        self.x=np.array(proj(self.x-self.step_size*grad)).reshape(-1,1)\n",
    "        return\n",
    "    \n",
    "    def update_COCO(self, cost_val, constr_val):\n",
    "        self.Q = self.Q+constr_val\n",
    "        self.TotalCost=self.TotalCost+cost_val ## updating the total violation and cost\n",
    "    \n",
    "    def surrogate_cost_grad(self, cost_grad, constr_grad): # returns the gradient of the surrogate cost function at x\n",
    "        grad=self.V*cost_grad.reshape(-1,1)+self.Lambda*np.exp(self.Lambda*self.Q)*constr_grad.reshape(-1,1)\n",
    "        self.grad_sum_sq=self.grad_sum_sq+np.linalg.norm(grad)**2\n",
    "        self.step_size=self.D/np.sqrt(2.0*self.grad_sum_sq) ### selecting step sizes using AdaGrad\n",
    "        return grad.reshape(-1,1)\n",
    "        \n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "exempt-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adversary_2Player:\n",
    "    \n",
    "    def __init__(self, n): # we are considering the single constraint case, i.e., m=1\n",
    "        self.n=n\n",
    "        self.A=np.random.randn(n,n)\n",
    "        self.C_x=np.random.rand(n,1)\n",
    "        self.C_y=np.random.rand(n,1)\n",
    "    \n",
    "    def grad_f(self, x):\n",
    "        best_action=np.argmax((self.A.T)@x) # computes the current best action of the adversary\n",
    "        return self.A[:,best_action].reshape(-1,1) # returns a column vector\n",
    "    \n",
    "    def f_val(self, x):\n",
    "        best_action=np.argmax((self.A.T)@x) # computes the current best action of the adversary\n",
    "        return (x.T@self.A[:,best_action])\n",
    "    \n",
    "    def grad_g(self, x):\n",
    "        best_action=np.argmax((self.A.T)@x) # computes the current best action of the adversary\n",
    "        if self.C_x.T@x+self.C_y[best_action]-1>0:\n",
    "            return self.C_x.reshape(-1,1)\n",
    "        else:\n",
    "            return np.zeros([int(self.n),1])\n",
    "    \n",
    "    def g_val(self,x):\n",
    "        best_action=np.argmax((self.A.T)@x) # computes the current best action of the adversary\n",
    "        return(max(0,self.C_x.T@x+self.C_y[best_action]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sealed-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adversary_Test:\n",
    "### solving the following problem\n",
    "### https://www.wolframalpha.com/input?i=minimize+e%5Ex%2By%5E2%2C+s.t.+x%2By%3D1%2C+x%3E%3D0%2C+y%3E%3D0%2C+x%5E2%2B2.5*y%5E2%3C%3D1\n",
    "    def __init__(self,n):\n",
    "        self.n=n\n",
    "        \n",
    "    def grad_f(self, x):\n",
    "        return np.array([np.exp(x[0]), 2*x[1]]).reshape(-1,1)\n",
    "    \n",
    "    def grad_g(self, x):\n",
    "        if x[0]**2+2.5*x[1]**2-1>=0:\n",
    "            return np.array([2.0*x[0], 5*x[1]]).reshape(-1,1)\n",
    "        else:\n",
    "            return np.zeros([self.n,1])\n",
    "                             \n",
    "    def f_val(self,x):\n",
    "        return (np.exp(x[0])+x[1]**2)\n",
    "                             \n",
    "    def g_val(self, x):\n",
    "        return max(0, x[0]**2+2.5*x[1]**2-1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "treated-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Implements the driver code\n",
    "\n",
    "T=10000 # number of steps -- seems like T needs to be large for the constraint to be satisfied if the cost function\n",
    "## is not strongly convex\n",
    "n=2   # dimension of the action\n",
    "\n",
    "coco = COCO(n,T) ### Algorithm object\n",
    "adversary= Adversary_Test(n) ### Adversary object\n",
    "\n",
    "for t in range(T):\n",
    "    current_action=coco.x # getting the current action of the algorithm\n",
    "\n",
    "    cost_grad=adversary.grad_f(current_action)\n",
    "    constr_grad=adversary.grad_g(current_action)\n",
    "    cost_val=adversary.f_val(current_action)\n",
    "    constr_val=adversary.g_val(current_action)  ### getting adversary's choices\n",
    "    \n",
    "    coco.update_COCO(cost_val, constr_val) ### updating internal states of the algorithm\n",
    "    surrogate_cost_grad=coco.surrogate_cost_grad(cost_grad, constr_grad) ### computing the gradient of the surrogate cost\n",
    "    \n",
    "    coco.predict_COCO(surrogate_cost_grad)  ### predicting the next_action\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "second-microphone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99997624])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(coco.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "removed-thesaurus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42839536],\n",
       "       [0.57158088]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-transcript",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
