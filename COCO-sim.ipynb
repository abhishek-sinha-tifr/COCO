{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading the required libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.core.common import flatten\n",
    "np.random.seed(7) ## n=100 and seed=5,7 seems to be working for violation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "device = torch.device('cpu') ## Running on cpu\n",
    "\n",
    "# Appropriate projection modules are now loaded by the adversary objects themselves\n",
    "#from projection import projection_simplex_bisection as proj ### loading the simplex projection module\n",
    "#from projection import euclidean_projection as proj ### loading the Euclidean projection module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-adoption",
   "metadata": {},
   "outputs": [],
   "source": [
    "class COCO:\n",
    "    def __init__(self, n, T): ### n denotes the dimension of input\n",
    "        #self.D=np.sqrt(2) ### D denotes the Euclidean diameter of the feasible set, which is sqrt(2) for simplex\n",
    "        self.D=20 ### Diameter of the set for banknote classification\n",
    "        self.n=n \n",
    "        #self.x=np.array(proj(np.random.rand(n))).reshape(-1,1) ### n denotes the input dimension\n",
    "        self.x=np.array(proj(np.ones(n)/n)).reshape(-1,1)\n",
    "        self.step_size=0\n",
    "        self.grad_sum_sq=0 ### internal variable needed to compute the step size\n",
    "        self.sum_x=self.x ### internal variable required to get the average prediction\n",
    "        self.Q=0 ### initializing the cumulative constraint violation\n",
    "        self.TotalCost=0 ### initializing the total cost incurred\n",
    "        self.Lambda=1.0/(2*np.sqrt(T)) \n",
    "        self.V=1   ## setting the required parameters\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    def predict_COCO(self, grad):\n",
    "        self.x=np.array(proj(self.x-self.step_size*grad)).reshape(-1,1)\n",
    "        return\n",
    "    \n",
    "    def update_COCO(self, cost_val, constr_val):\n",
    "        self.Q = self.Q+constr_val\n",
    "        self.TotalCost=self.TotalCost+cost_val ## updating CCV and cost\n",
    "        self.sum_x=self.sum_x+self.x\n",
    "    \n",
    "    def surrogate_cost_grad(self, cost_grad, constr_grad): # returns the gradient of the surrogate cost function at x\n",
    "        grad=self.V*cost_grad.reshape(-1,1)+self.Lambda*np.exp(self.Lambda*self.Q)*constr_grad.reshape(-1,1)\n",
    "        self.grad_sum_sq=self.grad_sum_sq+np.linalg.norm(grad)**2\n",
    "        self.step_size=self.D/np.sqrt(2.0*self.grad_sum_sq) ### selecting step sizes using AdaGrad\n",
    "        return grad.reshape(-1,1)\n",
    "        \n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adversary_2Player:\n",
    "    \n",
    "    def __init__(self, n): # we are considering the single constraint case, i.e., m=1\n",
    "        self.n=n\n",
    "        self.id='2Player'\n",
    "        self.problem_class='game'\n",
    "        self.A=np.random.randn(n,n)\n",
    "        self.C_x=np.random.rand(n,1)\n",
    "        self.C_y=0.5*np.random.rand(n,1)  ## forcing a strict feasibility on every round\n",
    "        self.cost_grad_sum=np.zeros([n,1]) ## state variable used to compute regret\n",
    "    \n",
    "    def grad_f(self, x):\n",
    "        best_action=np.argmax((self.A.T)@x) # computes the current best action of the adversary\n",
    "        self.cost_grad_sum+=self.A[:,best_action].reshape(-1,1) # updating the sum of gradients of cost\n",
    "        return self.A[:,best_action].reshape(-1,1) # returns a column vector\n",
    "    \n",
    "    def f_val(self, x):\n",
    "        best_action=np.argmax((self.A.T)@x) # computes the current best action of the adversary\n",
    "        return (x.T@self.A[:,best_action])\n",
    "    \n",
    "    def grad_g(self, x):\n",
    "        best_action=np.argmax((self.A.T)@x) # computes the current best action of the adversary\n",
    "        if self.C_x.T@x+self.C_y[best_action]-1>0:\n",
    "            return self.C_x.reshape(-1,1)\n",
    "        else:\n",
    "            return np.zeros([int(self.n),1])\n",
    "    \n",
    "    def g_val(self,x):\n",
    "        best_action=np.argmax((self.A.T)@x) # computes the current best action of the adversary\n",
    "        return(max(0,self.C_x.T@x+self.C_y[best_action]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-assembly",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adversary_Test:\n",
    "### solving the following offline optimization problem\n",
    "### https://www.wolframalpha.com/input?i=minimize+e%5Ex%2By%5E2%2C+s.t.+x%2By%3D1%2C+x%3E%3D0%2C+y%3E%3D0%2C+x%5E2%2B2.5*y%5E2%3C%3D1\n",
    "    def __init__(self,n):\n",
    "        self.n=n\n",
    "        self.problem_class='Test'\n",
    "        self.id='Test'\n",
    "\n",
    "        \n",
    "    def grad_f(self, x):\n",
    "        return np.array([np.exp(x[0]), 2*x[1]]).reshape(-1,1)\n",
    "    \n",
    "    def grad_g(self, x):\n",
    "        if x[0]**2+2.5*x[1]**2-1>=0:\n",
    "            return np.array([2.0*x[0], 5*x[1]]).reshape(-1,1)\n",
    "        else:\n",
    "            return np.zeros([self.n,1])\n",
    "                             \n",
    "    def f_val(self,x):\n",
    "        return (np.exp(x[0])+x[1]**2)\n",
    "                             \n",
    "    def g_val(self, x):\n",
    "        return max(0, x[0]**2+2.5*x[1]**2-1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-yacht",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adversary_classification:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.problem_class='classification'\n",
    "        self.t=-1 ### counter indicates the current round number\n",
    "        self.MISS=0 ## counter to keep track of number of misses\n",
    "        self.N1=0 ## count of examples belonging to class 1\n",
    "        self.FA=0 ### counter to keep track of number of FA\n",
    "        self.N0=0 ## count of examples belonging to class 0\n",
    "        \n",
    "    \n",
    "    def grad_f(self, x):\n",
    "        self.t+=1 # the counter is incremented when a call to grad_f is made\n",
    "        hat_y=float(1.0/(1+np.exp(self.z[self.t,:]@x))) # computing the predicted value\n",
    "        return (-(1-self.y[self.t])*(hat_y)*self.z[self.t,:]).reshape(-1,1) ## computing from f defined below\n",
    "        \n",
    "    \n",
    "    def grad_g(self, x):\n",
    "        hat_y=float(1.0/(1+np.exp(self.z[self.t,:]@x))) # computing the predicted value\n",
    "        return (self.y[self.t]*(1-hat_y)*self.z[self.t,:]).reshape(-1,1) ## computing from g defined below\n",
    "        \n",
    "    \n",
    "    def f_val(self, x):\n",
    "        hat_y=float(1.0/(1+np.exp(self.z[self.t,:]@x))) # computing the predicted value\n",
    "        self.N0+=(1-self.y[self.t])\n",
    "        self.FA+=(1-self.y[self.t])*hat_y\n",
    "        self.N1+=self.y[self.t]\n",
    "        self.MISS+=self.y[self.t]*(1-hat_y)\n",
    "        return -(1-self.y[self.t])*np.log(1-hat_y) ## f= -(1-y)log(1-y_hat) (ML est)\n",
    "    \n",
    "    def g_val(self, x):\n",
    "        bias=np.log(0.999999) ## can make bias=0\n",
    "        hat_y=float(1.0/(1+np.exp(self.z[self.t,:]@x))) # computing the predicted value\n",
    "        return -self.y[self.t]*(np.log(hat_y)-bias) ## g = -y * (log(y_hat) - log(target_prob) (ML est)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-alias",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Banknote(Adversary_classification):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.id='banknote'\n",
    "        self.data=pd.read_csv('data/data_banknote_authentication.txt')\n",
    "        self.data.columns=['variance', 'skewness', 'curtosis', 'entropy', 'label']\n",
    "        self.data=self.data.sample(frac=1) ## randomly shuffling the rows\n",
    "        \n",
    "        self.z=np.array(self.data.iloc[:,0:4]) ## z denotes the feature vector matrix\n",
    "        ### appending an all-one column to account for the intercept term\n",
    "        #l=pd.DataFrame(np.ones(len(self.data)))\n",
    "        #self.z=np.append(self.z, l, axis=1)\n",
    "        \n",
    "        \n",
    "        object= StandardScaler()\n",
    "        self.z= object.fit_transform(self.z) ## preprocessing the feature vectors \n",
    "        self.y=np.array(self.data['label'])    ## y denotes the column of labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearSep(Adversary_classification):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.id='linsep'\n",
    "        self.data=pd.read_csv('data/large_linearly_separable_data.csv')\n",
    "        self.data=self.data.sample(frac=1) ## randomly shuffling the rows\n",
    "        self.z=np.array(self.data.iloc[:,0:2]) ## z denotes the feature vector matrix\n",
    "        ### appending an all-one column to account for the intercept term\n",
    "        #l=pd.DataFrame(np.ones(len(self.data)))\n",
    "        #self.z=np.append(self.z, l, axis=1)\n",
    "        \n",
    "        \n",
    "        object= StandardScaler()\n",
    "        self.z= object.fit_transform(self.z) ## preprocessing the feature vectors \n",
    "        self.y=np.array(self.data['Label'])    ## y denotes the column of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisDataset(Adversary_classification):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.id='iris'\n",
    "        self.data=pd.read_csv('data/Iris.csv')\n",
    "        self.data=self.data.replace('Iris-setosa', 0)\n",
    "        self.data=self.data.replace('Iris-versicolor', 1)\n",
    "        self.data=self.data.replace('Iris-virginica', 2)\n",
    "        self.data=self.data[self.data['Species']<1.5]\n",
    "        \n",
    "        self.data=self.data.sample(frac=1) ## randomly shuffling the rows\n",
    "        self.z=np.array(self.data.iloc[:,1:5]) ## z denotes the feature vector matrix\n",
    "        ### appending an all-one column to account for the intercept term\n",
    "        #l=pd.DataFrame(np.ones(len(self.data)))\n",
    "        #self.z=np.append(self.z, l, axis=1)\n",
    "        \n",
    "        \n",
    "        object= StandardScaler()\n",
    "        self.z= object.fit_transform(self.z) ## preprocessing the feature vectors \n",
    "        self.y=np.array(self.data['Species'])    ## y denotes the column of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-hamilton",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN: \n",
    "    ## implements the case when the cost and constraint functions are given by a DNN\n",
    "    def __init__(self):\n",
    "        self.id='NN'\n",
    "        self.problem_class='classification'\n",
    "        self.t=-1 ### counter indicates the current round number\n",
    "        self.MISS=0 ## counter to keep track of number of misses\n",
    "        self.N1=0 ## count of examples belonging to class 1\n",
    "        self.FA=0 ### counter to keep track of number of FA\n",
    "        self.N0=0 ## count of examples belonging to class 0\n",
    "        \n",
    "        ## loading data\n",
    "        ##---------------\n",
    "        self.data=pd.read_csv('data/large_linearly_separable_data.csv')\n",
    "        self.data=self.data.sample(frac=1) ## randomly shuffling the rows\n",
    "        self.z=np.array(self.data.iloc[:,0:2]) ## z denotes the feature vector matrix\n",
    "        object= StandardScaler()\n",
    "        self.z= object.fit_transform(self.z) ## preprocessing the feature vectors \n",
    "        self.y=np.array(self.data['Label'])    ## y denotes the column of labels\n",
    "        #### -------------\n",
    "        ## configuring the NN architecture and the loss function\n",
    "        \n",
    "        self.N, self.D_in, self.H, self.D_out = 1, self.z.shape[1], 100, 1 ## 100 hidden layer width, 4 dimensional feature\n",
    "        \n",
    "        self.model = torch.nn.Sequential(\n",
    "          torch.nn.Linear(self.D_in, self.H),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(self.H, self.D_out),\n",
    "          torch.nn.Sigmoid(), ## the output layer\n",
    "        ).to(device)\n",
    "        \n",
    "        self.loss_fn = torch.nn.BCELoss() ## remember - it is simply the negative log likelihood - training via Max likelihood\n",
    "        \n",
    "    def update_grad(self):\n",
    "        self.t+=1\n",
    "        self.model.zero_grad()\n",
    "        self.hat_y=self.model(torch.tensor(self.z[self.t,:]).to(torch.float32)) ## predicted value via forward pass\n",
    "        self.loss=self.loss_fn(self.hat_y, torch.tensor(self.y[self.t]).to(torch.float32))\n",
    "        self.loss.backward()\n",
    "        gradients = []\n",
    "        for param in self.model.parameters():\n",
    "            if param.grad is not None:\n",
    "                gradients.append(param.grad.view(-1))\n",
    "        self.grad_vector = np.array(torch.cat(gradients))\n",
    "        \n",
    "        \n",
    "    def grad_f(self, x):\n",
    "        if(self.y[self.t]==0):\n",
    "            return self.grad_vector\n",
    "        else:\n",
    "            return np.zeros(len(self.grad_vector))\n",
    "        \n",
    "    \n",
    "    def grad_g(self, x):\n",
    "        if(self.y[self.t]==1):\n",
    "            return np.array(self.grad_vector)\n",
    "        else:\n",
    "            return np.zeros(len(self.grad_vector))\n",
    "        \n",
    "        \n",
    "    \n",
    "    def f_val(self, x):\n",
    "        self.N0+=(1-self.y[self.t])\n",
    "        self.FA+=(1-self.y[self.t])*self.hat_y\n",
    "        self.N1+=self.y[self.t]\n",
    "        self.MISS+=self.y[self.t]*(1-self.hat_y)\n",
    "        return -(1-self.y[self.t])*torch.log(1-self.hat_y) ## f= -(1-y)log(1-y_hat) (Liklihood value)\n",
    "    \n",
    "    \n",
    "    def g_val(self, x):  ## g = -y log(y_hat) assuming bias=0\n",
    "        return -self.y[self.t]*(torch.log(self.hat_y))\n",
    "\n",
    "## parameter assignment method required in the NN class\n",
    "def assign_parameters(model, vector):\n",
    "    \"\"\"\n",
    "    Assign the parameters of a PyTorch neural network using the given vector.\n",
    "\n",
    "    Args:\n",
    "    - model (nn.Module): The PyTorch neural network model.\n",
    "    - vector (list or numpy array or torch tensor): The vector containing the new parameters.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    if not isinstance(vector, torch.Tensor):\n",
    "        vector = torch.tensor(vector, dtype=torch.float32)\n",
    "    \n",
    "    # Ensure the vector has the same number of elements as the model's parameters\n",
    "    params = torch.cat([p.view(-1) for p in model.model.parameters()])\n",
    "    assert params.numel() == vector.numel(), \"Vector size must match the number of model parameters\"\n",
    "    \n",
    "    # Assign the parameters\n",
    "    index = 0\n",
    "    for p in model.model.parameters():\n",
    "        numel = p.numel()\n",
    "        p.data = vector[index:index+numel].view(p.size())\n",
    "        index += numel\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Driver code\n",
    "#---------------------------\n",
    "\n",
    "## Choosing the problem instance\n",
    "\n",
    "#adversary= Adversary_Test(n) ### Adversary object\n",
    "#adversary=Banknote()\n",
    "#adversary=LinearSep()\n",
    "#adversary=Adversary_2Player(n=100)\n",
    "#adversary=IrisDataset()\n",
    "adversary=NN()\n",
    "\n",
    "if adversary.id=='2Player':\n",
    "    n=100\n",
    "    T=100000\n",
    "    from projection import projection_simplex_bisection as proj ### loading the simplex projection module\n",
    "elif adversary.id=='banknote':\n",
    "    T, n=adversary.z.shape\n",
    "    from projection import euclidean_projection as proj ### loading the Euclidean projection module\n",
    "elif adversary.id=='linsep':\n",
    "    T, n=adversary.z.shape\n",
    "    from projection import euclidean_projection as proj ### loading the Euclidean projection module\n",
    "elif adversary.id=='iris':\n",
    "    T, n=adversary.z.shape \n",
    "    from projection import euclidean_projection as proj ### loading the Euclidean projection module\n",
    "elif adversary.id=='NN':\n",
    "    T=adversary.z.shape[0]\n",
    "    grad_vec=[]\n",
    "    for param in adversary.model.parameters():\n",
    "        grad_vec.append(np.array(param.data))\n",
    "    n=len(list(flatten(grad_vec))) ## counting the number of parameters\n",
    "    from projection import euclidean_projection as proj ### loading the Euclidean projection module\n",
    "##########################if \n",
    "\n",
    "\n",
    "coco = COCO(n,T) ### Algorithm object\n",
    "\n",
    "\n",
    "cost_vec=np.zeros([1,T])\n",
    "violation_vec=np.zeros([1,T]) ### Arrays to store the cumulative cost and violation incurred by COCO\n",
    "regret_vec=np.zeros([1,T])\n",
    "\n",
    "for t in range(T):\n",
    "    current_action=coco.x # getting the current action of the algorithm\n",
    "    \n",
    "    ## assigning the parameters to the NN object \n",
    "    \n",
    "    if adversary.id=='NN':\n",
    "        assign_parameters(adversary, current_action)\n",
    "        adversary.update_grad()\n",
    "        \n",
    "    ## Calling adversary to get its choice of cost and constraint functions    \n",
    "    cost_grad=adversary.grad_f(current_action)\n",
    "    constr_grad=adversary.grad_g(current_action)\n",
    "    cost_val=adversary.f_val(current_action)\n",
    "    constr_val=adversary.g_val(current_action)  ### getting adversary's choices\n",
    "    \n",
    "    if adversary.id=='NN':\n",
    "        constr_val=constr_val.item()\n",
    "    \n",
    "    ## Calling COCO to update its internal states and to determine its next action\n",
    "    coco.update_COCO(cost_val, constr_val) ### updating internal states of the algorithm\n",
    "    surrogate_cost_grad=coco.surrogate_cost_grad(cost_grad, constr_grad) ### computing the gradient of the surrogate cost\n",
    "    \n",
    "    coco.predict_COCO(surrogate_cost_grad)  ### predicting the next_action\n",
    "    \n",
    "    #### recording the statistics\n",
    "    cost_vec[0,t]=coco.TotalCost\n",
    "    violation_vec[0,t]=coco.Q\n",
    "    if adversary.problem_class=='game':\n",
    "        regret_vec[0,t]=coco.TotalCost - min(adversary.cost_grad_sum) ## this is a little erroneous as it computes regret over the entire admissible set\n",
    "   \n",
    " #### computing the number of classification errors\n",
    "if adversary.problem_class=='classification':\n",
    "    print('False Alarm rate:',  adversary.FA/adversary.N0, 'Miss rate:', adversary.MISS/adversary.N1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-louisiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plotting the results\n",
    "#import pylab \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['text.usetex'] = True\n",
    "#sns.set(style='ticks', palette='Set2')\n",
    "sns.set()\n",
    "\n",
    "sns.set_theme(\"paper\")\n",
    "sns.set_style(\"dark\")\n",
    "#sns.color_palette(\"gist_heat\")\n",
    "\n",
    "#ax = plt.plot(figsize=(10,6))\n",
    "#pylab.figure(1)\n",
    "#pylab.plot(range(T), violation_vec.T)\n",
    "#pylab.figure(2)\n",
    "#pylab.plot(range(T), regret_vec.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pylab.figure(2)\n",
    "#pylab.plot(range(T), cost_vec.T)\n",
    "#sum(coco.x)\n",
    "#plt.figure(dpi=1000)\n",
    "plt.ylabel(\"Cost\", fontsize=15)\n",
    "plt.xlabel(\"Rounds\", fontsize=15)\n",
    "plt.plot(range(T), cost_vec.T, linewidth = 1.8)\n",
    "plt.grid(linestyle = '--', linewidth = 0.7)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.suptitle('Variation of Cost', fontsize=20)\n",
    "plt.savefig('Cost_variation_plt', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-accused",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(dpi=1000)\n",
    "plt.ylabel(\"CCV\", fontsize=18)\n",
    "plt.xlabel(\"Rounds\", fontsize=18)\n",
    "plt.plot(range(T), violation_vec.T, linewidth = 2, linestyle='--')\n",
    "plt.grid(linestyle = '--', linewidth = 0.7)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.suptitle('Variation of CCV', fontsize=20)\n",
    "plt.savefig('CCV_variation_plt', dpi=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco.grad_sum_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-movement",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco.step_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary=NN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_vec=[]\n",
    "for param in adversary.model.parameters():\n",
    "    grad_vec.append(np.array(param.data))\n",
    "n=len(list(flatten(grad_vec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "from projection import euclidean_projection as proj\n",
    "T=adversary.z.shape[0]\n",
    "coco = COCO(n,T) ### Algorithm object\n",
    "x=coco.x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(adversary.model.parameters())[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=coco.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary.y[adversary.t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-closure",
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary.loss=adversary.loss_fn(hat_y, torch.tensor(adversary.y[adversary.t]).to(torch.float32))\n",
    "adversary.loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-technique",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(adversary.model.parameters())[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-cheese",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = []\n",
    "for param in adversary.model.parameters():\n",
    "    print(param.grad)\n",
    "    if param.grad is not None:\n",
    "        gradients.append(param.grad.view(-1))\n",
    "grad_vector = np.array(torch.cat(gradients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-uruguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary.t=234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary.model(torch.tensor(adversary.z[adversary.t,:]).to(torch.float32)) ## predicted value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary.hat_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-magnitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(adversary.y[adversary.t]).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary.model.zero_grad()\n",
    "adversary.loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-editing",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco.Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-tampa",
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary.update_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-privilege",
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary.loss_fn(adversary.hat_y, torch.tensor(adversary.y[adversary.t]).to(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-database",
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary.hat_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-milan",
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary.y[adversary.t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-times",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
